<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- Do not modify this file directly. Instead, copy entries that you -->
<!-- wish to modify from this file into hdfs-site.xml and change them -->
<!-- there. If hdfs-site.xml does not already exist, create it. -->
<configuration xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
    xsi:noNamespaceSchemaLocation="configuration.xsd">
    <property>
        <name>hadoop.namenode.memory</name>
        <value>0</value>
        <valuetype>Integer</valuetype>
        <type>1</type>
        <automatic>true</automatic>
        <reserved>true</reserved>
        <group>namenode</group>
        <definition>
            <en>Namenode server memory size</en>
        </definition>
        <description>
            <en>Default size for namenode server memory.</en>
        </description>
    </property>
    <property>
        <name>hadoop.secondary.namenode.memory</name>
        <value>0</value>
        <valuetype>Integer</valuetype>
        <type>1</type>
        <automatic>true</automatic>
        <reserved>true</reserved>
        <group>namenode</group>
        <definition>
            <en>Secondary namenode server memory size</en>
        </definition>
        <description>
            <en>Default size for secondary namenode server memory.</en>
        </description>
    </property>
    <property>
        <name>hadoop.datanode.memory</name>
        <value>4096</value>
        <valuetype>Integer</valuetype>
        <type>1</type>
        <automatic>true</automatic>
        <reserved>true</reserved>
        <group>datanode</group>
        <definition>
            <en>Datanode server memory size</en>
        </definition>
        <description>
            <en>Default size for datanode server memory.</en>
        </description>
    </property>
    <property>
        <name>dfs.namenode.logging.level</name>
        <value>info</value>
        <valuetype>String</valuetype>
        <group>namenode</group>
        <definition>
            <en>Namenode logging level</en>
        </definition>
        <description>
            <en>The logging level for dfs namenode. Other values are "dir"(trac
e namespace mutations), "block"(trace block under/over replications and block
creations/deletions), or "all".</en>
        </description>
    </property>
    <property>
        <name>dfs.secondary.http.address</name>
        <value>0.0.0.0:50090</value>
        <valuetype>String</valuetype>
        <enable>false</enable>
        <group>namenode</group>
        <definition>
            <en>Secondary namenode http server address and port</en>
        </definition>
        <description>
            <en>
    The secondary namenode http server address and port.
    If the port is 0 then the server will start on a free port.
</en>
        </description>
    </property>
    <property>
        <name>dfs.datanode.address</name>
        <value>0.0.0.0:50010</value>
        <valuetype>String</valuetype>
        <group>datanode</group>
        <definition>
            <en>Address datanode server listens to</en>
        </definition>
        <description>
            <en>
    The address where the datanode server will listen to.
    If the port is 0 then the server will start on a free port.
</en>
        </description>
    </property>
    <property>
        <name>dfs.datanode.http.address</name>
        <value>0.0.0.0:50075</value>
        <valuetype>String</valuetype>
        <group>datanode</group>
        <definition>
            <en>Datanode http server address and port</en>
        </definition>
        <description>
            <en>
    The datanode http server address and port.
    If the port is 0 then the server will start on a free port.
</en>
        </description>
    </property>
    <property>
        <name>dfs.datanode.ipc.address</name>
        <value>0.0.0.0:50020</value>
        <valuetype>String</valuetype>
        <group>datanode</group>
        <definition>
            <en>Datanode ipc server adderss and port</en>
        </definition>
        <description>
            <en>
    The datanode ipc server address and port.
    If the port is 0 then the server will start on a free port.
</en>
        </description>
    </property>
    <property>
        <name>dfs.block.local-path-access.user</name>
        <value></value>
        <recommendation>hbase</recommendation>
        <valuetype>String</valuetype>
        <group>datanode</group>
        <definition>
            <en>DFS short circuit read allowed user list</en>
        </definition>
        <description>
            <en>The user in this list can directly read the local file system HDFS block,
            instead of reading through DataNode, thus improving performance,
            The list is seperated by comma.</en>
        </description>
        <allowempty>true</allowempty>
    </property>
    <property>
        <name>dfs.datanode.handler.count</name>
        <value>3</value>
        <intel_default>3</intel_default>
        <recommendation>100</recommendation>
        <valuetype>Integer</valuetype>
        <group>datanode</group>
        <definition>
            <en>Datanode server threads count</en>
        </definition>
        <description>
            <en>The number of server threads for the datanode.</en>
        </description>
    </property>
    <property>
        <name>dfs.datanode.max.xcievers</name>
        <value>32768</value>
        <valuetype>Integer</valuetype>
        <group>datanode</group>
        <definition>
            <en>Datanode service threads count</en>
        </definition>
        <description>
            <en>Number of threads for the datanode service.</en>
        </description>
    </property>
    <property>
        <name>dfs.http.address</name>
        <value>0.0.0.0:50070</value>
        <valuetype>String</valuetype>
        <enable>false</enable>
        <group>basic</group>
        <definition>
            <en>Namenode Web UI address and port</en>
        </definition>
        <description>
            <en>
    The address and the base port where the dfs namenode web ui will listen on.
    If the port is 0 then the server will start on a free port.
</en>
        </description>
    </property>
    <property>
        <name>dfs.https.enable</name>
        <value>false</value>
        <valuetype>Boolean</valuetype>
        <group>security</group>
        <definition>
            <en>Whether to support HTTPS</en>
        </definition>
        <description>
            <en>Decide if HTTPS(SSL) is supported on HDFS
</en>
        </description>
    </property>
    <property>
        <name>dfs.https.need.client.auth</name>
        <value>false</value>
        <valuetype>Boolean</valuetype>
        <group>security</group>
        <definition>
            <en>Whether require SSL client certificate authentication</en>
        </definition>
        <description>
            <en>Whether SSL client certificate authentication is required
</en>
        </description>
    </property>
    <property>
        <name>dfs.https.server.keystore.resource</name>
        <value>ssl-server.xml</value>
        <valuetype>String</valuetype>
        <group>security</group>
        <definition>
            <en>Resource file to extract SSL server keystore information</en>
        </definition>
        <description>
            <en>Resource file from which ssl server keystore
  information will be extracted
</en>
        </description>
    </property>
    <property>
        <name>dfs.https.client.keystore.resource</name>
        <value>ssl-client.xml</value>
        <valuetype>String</valuetype>
        <group>security</group>
        <definition>
            <en>Resource file to extract SSL client keystore information</en>
        </definition>
        <description>
            <en>Resource file from which ssl client keystore
  information will be extracted
</en>
        </description>
    </property>
    <property>
        <name>dfs.datanode.https.address</name>
        <value>0.0.0.0:50475</value>
        <valuetype>String</valuetype>
        <group>datanode</group>
        <definition>
            <en>Datanode https server address and port</en>
        </definition>
        <description>
            <en>
    The datanode https server address and port.
    If the port is 0 then the server will start on a free port.
</en>
        </description>
    </property>
    <property>
        <name>dfs.https.address</name>
        <value>0.0.0.0:50470</value>
        <valuetype>String</valuetype>
        <group>basic</group>
        <definition>
            <en>dfs https address and port</en>
        </definition>
        <description>
            <en>dfs https address and port</en>
        </description>
    </property>
    <property>
        <name>dfs.datanode.dns.interface</name>
        <value>default</value>
        <valuetype>String</valuetype>
        <group>datanode</group>
        <definition>
            <en>Network Interface name from which Datanode should report its IP address</en>
        </definition>
        <description>
            <en>The name of the Network Interface from which a data node should
  report its IP address.
</en>
        </description>
    </property>
    <property>
        <name>dfs.datanode.dns.nameserver</name>
        <value>default</value>
        <valuetype>String</valuetype>
        <group>datanode</group>
        <definition>
            <en>Datanode name server address</en>
        </definition>
        <description>
            <en>The host name or IP address of the name server (DNS)
  which a DataNode should use to determine the host name used by the
  NameNode for communication and display purposes.
</en>
        </description>
    </property>
    <property>
        <name>dfs.replication.considerLoad</name>
        <value>true</value>
        <valuetype>Boolean</valuetype>
        <group>perf</group>
        <definition>
            <en>Whether chooseTarget considers the target's load or not</en>
        </definition>
        <description>
            <en>Decide if chooseTarget considers the target's load or not
</en>
        </description>
    </property>
    <property>
        <name>dfs.default.chunk.view.size</name>
        <value>32768</value>
        <valuetype>Integer</valuetype>
        <group>basic</group>
        <definition>
            <en>Chunk size to view on a browser</en>
        </definition>
        <description>
            <en>The number of bytes to view for a file on the browser.
</en>
        </description>
    </property>
    <property>
        <name>dfs.datanode.du.reserved</name>
        <value>0</value>
        <valuetype>Integer</valuetype>
        <group>datanode</group>
        <definition>
            <en>Reserved space in bytes per volume</en>
        </definition>
        <description>
            <en>Reserved space in bytes per volume. Always leave this much space free for non dfs use.
</en>
        </description>
    </property>
    <property>
        <name>dfs.name.dir</name>
        <value>/hadoop/drbd/hadoop_image,/hadoop/hadoop_image_local</value>
        <valuetype>Directory</valuetype>
        <group>basic</group>
        <definition>
            <en>DFS fsimage file directory</en>
        </definition>
        <description>
            <en>Determines where on the local filesystem the DFS name node
      should store the name table(fsimage).  If this is a comma-delimited list
      of directories then the name table is replicated in all of the
      directories, for redundancy. </en>
        </description>
    <sectionname>NameNode-system</sectionname>
    <form>TextItem</form>
    </property>
    <property>
        <name>dfs.name.edits.dir</name>
        <value>${dfs.name.dir}</value>
        <valuetype>Directory</valuetype>
        <group>basic</group>
        <definition>
            <en>DFS edits file directory</en>
        </definition>
        <description>
            <en>Determines where on the local filesystem the DFS name node
      should store the transaction (edits) file. If this is a comma-delimited list
      of directories then the transaction file is replicated in all of the
      directories, for redundancy. Default value is same as dfs.name.dir
</en>
        </description>
    </property>
    <property>
        <name>dfs.web.ugi</name>
        <value>webuser,webgroup</value>
        <valuetype>String</valuetype>
        <group>basic</group>
        <definition>
            <en>user account used by the web interface</en>
        </definition>
        <description>
            <en>The user account used by the web interface.
    Syntax: USERNAME,GROUP1,GROUP2, ...
</en>
        </description>
    </property>
    <property>
        <name>dfs.permissions</name>
        <readonly>true</readonly>
        <value>true</value>
        <valuetype>Boolean</valuetype>
        <group>security</group>
        <definition>
            <en>Whether enable permission checking in HDFS</en>
        </definition>
        <description>
            <en>
    If "true", enable permission checking in HDFS.
    If "false", permission checking is turned off,
    but all other behavior is unchanged.
    Switching from one parameter value to the other does not change the mode,
    owner or group of files or directories.
</en>
        </description>
    </property>
    <property>
        <name>dfs.permissions.extended</name>
        <readonly>true</readonly>
        <value>false</value>
        <valuetype>Boolean</valuetype>
        <group>security</group>
        <definition>
            <en>Whether to enable permission extension in HDFS</en>
        </definition>
        <description>
            <en>
    If "true", enable permission extension in HDFS.
    If "false", permission extension is turned off.
</en>
        </description>
    </property>
    <property>
        <name>dfs.permissions.extended.permissions.file</name>
        <readonly>true</readonly>
        <value></value>
        <valuetype>String</valuetype>
        <allowempty>true</allowempty>
        <group>security</group>
        <definition>
            <en>Configuration file for extension rules</en>
        </definition>
        <description>
            <en>
    If extended permissions is enabled, then the needed configuration file should be
    configured here for extension rules.
</en>
        </description>
    </property>
    <property>
        <name>dfs.permissions.supergroup</name>
        <value>supergroup</value>
        <valuetype>String</valuetype>
        <group>security</group>
        <definition>
            <en>super-users group name</en>
        </definition>
        <description>
            <en>The name of the group of super-users.</en>
        </description>
    </property>
    <property>
        <name>dfs.block.access.token.enable</name>
        <value>false</value>
        <valuetype>Boolean</valuetype>
        <group>security</group>
        <definition>
            <en>Access tokens for accessing datanodes</en>
        </definition>
        <description>
            <en>
    If "true", access tokens are used as capabilities for accessing datanodes.
    If "false", no access tokens are checked on accessing datanodes.
</en>
        </description>
    </property>
    <property>
        <name>dfs.block.access.key.update.interval</name>
        <value>600</value>
        <valuetype>Integer</valuetype>
        <group>security</group>
        <definition>
            <en>Interval at which namenode updates its access keys</en>
        </definition>
        <description>
            <en>
    Interval in minutes at which namenode updates its access keys.
</en>
        </description>
    </property>
    <property>
        <name>dfs.block.access.token.lifetime</name>
        <value>600</value>
        <valuetype>Integer</valuetype>
        <group>security</group>
        <definition>
            <en>Access tokens lifetime</en>
        </definition>
        <description>
            <en>The lifetime of access tokens in minutes.</en>
        </description>
    </property>
    <property>
        <name>dfs.data.dir</name>
        <value>${hadoop.tmp.dir}/dfs/data</value>
        <intel_default>${hadoop.tmp.dir}/dfs/data</intel_default>
        <recommendation></recommendation>
        <valuetype>Directory</valuetype>
        <allowempty>false</allowempty>
        <script>'export dirs=`ruby /usr/lib/intelcloud/scripts/mounts.rb 2>/dev/null`;if [ "$dirs" == "" ]; then echo "/hadoop/data"; else for dir in $dirs; do echo $dir/hadoop/data; done; fi' </script>
        <group>basic</group>
        <definition>
            <en>Local filesystem directory datanode stores its blocks</en>
        </definition>
        <description>
            <en>Determines where on the local filesystem an DFS data node
  should store its blocks.  If this is a comma-delimited
  list of directories, then data will be stored in all named
  directories, typically on different devices.
  Directories that do not exist are ignored.
</en>
        </description>
        <type>2</type>
    </property>
    <property>
        <name>dfs.datanode.data.dir.perm</name>
        <value>755</value>
        <intel_default>755</intel_default>
        <recommendation>755</recommendation>
        <valuetype>Integer</valuetype>
        <group>security</group>
        <definition>
            <en>Local filesystem directory permissions</en>
        </definition>
        <description>
            <en>Permissions for the directories on on the local filesystem where
  the DFS data node store its blocks. The permissions can either be octal or
  symbolic.</en>
        </description>
    </property>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
        <valuetype>Integer</valuetype>
        <group>basic</group>
        <definition>
            <en>Block replication count</en>
        </definition>
        <description>
            <en>Default block replication.
  The actual number of replications can be specified when the file is created.
  The default is used if replication is not specified in create time.
</en>
        </description>
    <sectionname>basic</sectionname>
    <form>TextItem</form>
    </property>
    <property>
        <name>dfs.replication.max</name>
        <value>512</value>
        <valuetype>Integer</valuetype>
        <group>basic</group>
        <definition>
            <en>Maximal block replication count</en>
        </definition>
        <description>
            <en>Maximal block replication.
</en>
        </description>
    </property>
    <property>
        <name>dfs.replication.min</name>
        <value>1</value>
        <valuetype>Integer</valuetype>
        <group>basic</group>
        <definition>
            <en>Minimal block replication count</en>
        </definition>
        <description>
            <en>Minimal block replication.
</en>
        </description>
    </property>
    <property>
        <name>dfs.block.size</name>
        <value>67108864</value>
        <intel_default>67108864</intel_default>
        <recommendation>134217728</recommendation>
        <valuetype>Integer</valuetype>
        <group>basic</group>
        <definition>
            <en>Default block size</en>
        </definition>
        <description>
            <en>The default block size for new files.</en>
        </description>
    <sectionname>basic</sectionname>
    <form>TextItem</form>
    </property>
    <property>
        <name>dfs.df.interval</name>
        <value>60000</value>
        <valuetype>Integer</valuetype>
        <group>basic</group>
        <definition>
            <en>Disk usage statistics refresh interval</en>
        </definition>
        <description>
            <en>Disk usage statistics refresh interval in msec.</en>
        </description>
    </property>
    <property>
        <name>dfs.client.block.write.retries</name>
        <value>3</value>
        <valuetype>Integer</valuetype>
        <group>perf</group>
        <definition>
            <en>Writing to datanodes retry times</en>
        </definition>
        <description>
            <en>The number of retries for writing blocks to the data nodes,
  before we signal failure to the application.
</en>
        </description>
    </property>
    <property>
        <name>dfs.blockreport.intervalMsec</name>
        <value>3600000</value>
        <valuetype>Integer</valuetype>
        <group>basic</group>
        <definition>
            <en>Block reporting interval</en>
        </definition>
        <description>
            <en>Determines block reporting interval in milliseconds.</en>
        </description>
    </property>
    <property>
        <name>dfs.blockreport.initialDelay</name>
        <value>0</value>
        <valuetype>Integer</valuetype>
        <group>basic</group>
        <definition>
            <en>Delay for first block report</en>
        </definition>
        <description>
            <en>Delay for first block report in seconds.</en>
        </description>
    </property>
    <property>
        <name>dfs.datanode.directoryscan.interval</name>
        <value>21600</value>
        <valuetype>Integer</valuetype>
        <group>datanode</group>
        <definition>
            <en>Datanode scan data interval</en>
        </definition>
        <description>
            <en>Interval in seconds for Datanode to scan data directories and
  reconcile the difference between blocks in memory and on the disk.
</en>
        </description>
    </property>
    <property>
        <name>dfs.datanode.directoryscan.threads</name>
        <value>1</value>
        <valuetype>Integer</valuetype>
        <group>datanode</group>
        <definition>
            <en>Number of threads to use when scanning volumes to
  generate block reports</en>
        </definition>
        <description>
            <en>Number of threads to use when scanning volumes to
  generate block reports. A value greater than one means
  volumes will be scanned in parallel.</en>
        </description>
    </property>
    <property>
        <name>dfs.heartbeat.interval</name>
        <value>3</value>
        <valuetype>Integer</valuetype>
        <group>datanode</group>
        <definition>
            <en>Datanode heartbeat</en>
        </definition>
        <description>
            <en>Determines datanode heartbeat interval in seconds.</en>
        </description>
    </property>
    <property>
        <name>dfs.namenode.handler.count</name>
        <value>10</value>
        <intel_default>10</intel_default>
        <recommendation>100</recommendation>
        <valuetype>Integer</valuetype>
        <group>namenode</group>
        <definition>
            <en>Namenode server threads count</en>
        </definition>
        <description>
            <en>The number of server threads for the namenode.</en>
        </description>
        <sectionname>NameNode-system</sectionname>
        <form>TextItem</form>
    </property>
    <property>
        <name>dfs.safemode.threshold.pct</name>
        <value>0.999f</value>
        <valuetype>Float</valuetype>
        <group>basic</group>
        <definition>
            <en>percentage of blocks that should satisfy
    the minimal replication requirement defined by dfs.replication.min.
</en>
        </definition>
        <description>
            <en>
    Specifies the percentage of blocks that should satisfy
    the minimal replication requirement defined by dfs.replication.min.
    Values less than or equal to 0 mean not to wait for any particular
    percentage of blocks before exiting safemode.
    Values greater than 1 will make safe mode permanent.
</en>
        </description>
    </property>
    <property>
        <name>dfs.safemode.min.datanodes</name>
        <value>0</value>
        <valuetype>Integer</valuetype>
        <hide>true</hide>
        <group>basic</group>
        <definition>
            <en>number of datanodes that must be considered alive
    before the name node exits safemode.</en>
        </definition>
        <description>
            <en>
    Specifies the number of datanodes that must be considered alive
    before the name node exits safemode.
    Values less than or equal to 0 mean not to take the number of live
    datanodes into account when deciding whether to remain in safe mode
    during startup.
    Values greater than the number of datanodes in the cluster
    will make safe mode permanent.
</en>
        </description>
    </property>
    <property>
        <name>dfs.safemode.extension</name>
        <value>30000</value>
        <valuetype>Integer</valuetype>
        <group>basic</group>
        <definition>
            <en>Safe mode extension time</en>
        </definition>
        <description>
            <en>
    Determines extension of safe mode in milliseconds
    after the threshold level is reached.
</en>
        </description>
    </property>
    <property>
        <name>dfs.balance.bandwidthPerSec</name>
        <value>1048576</value>
        <intel_default>1048576</intel_default>
        <recommendation>104857600</recommendation>
        <valuetype>Integer</valuetype>
        <group>datanode</group>
        <definition>
            <en>Maximal amount of bandwidth that each datanode
        can utilize for the balancing purpose</en>
        </definition>
        <description>
            <en>
        Specifies the maximal amount of bandwidth that each datanode
        can utilize for the balancing purpose in terms of
        the number of bytes per second.
</en>
        </description>
    </property>
    <property>
        <name>dfs.hosts</name>
        <value></value>
        <valuetype>String</valuetype>
        <allowempty>true</allowempty>
        <group>basic</group>
        <definition>
            <en>File that contains a list of hosts
  permitted to connect to the namenode</en>
        </definition>
        <description>
            <en>Names a file that contains a list of hosts that are
  permitted to connect to the namenode. The full pathname of the file
  must be specified.  If the value is empty, all hosts are
  permitted.</en>
        </description>
    </property>
    <property>
        <name>dfs.hosts.exclude</name>
        <value></value>
        <valuetype>String</valuetype>
        <allowempty>true</allowempty>
        <group>basic</group>
        <definition>
            <en>File that contains a list of hosts
  not permitted to connect to the namenode</en>
        </definition>
        <description>
            <en>Names a file that contains a list of hosts that are
  not permitted to connect to the namenode.  The full pathname of the
  file must be specified.  If the value is empty, no hosts are
  excluded.</en>
        </description>
    </property>
    <property>
        <name>dfs.max.objects</name>
        <value>0</value>
        <valuetype>Integer</valuetype>
        <group>basic</group>
        <definition>
            <en>The maximum number of files, directories and blocks
  dfs supports</en>
        </definition>
        <description>
            <en>The maximum number of files, directories and blocks
  dfs supports. A value of zero indicates no limit to the number
  of objects that dfs supports.
</en>
        </description>
    </property>
    <property>
        <name>dfs.namenode.decommission.interval</name>
        <value>30</value>
        <valuetype>Integer</valuetype>
        <group>namenode</group>
        <definition>
            <en>Namenode periodicity to check if decommission is complete</en>
        </definition>
        <description>
            <en>Namenode periodicity in seconds to check if decommission is
  complete.</en>
        </description>
    </property>
    <property>
        <name>dfs.namenode.decommission.nodes.per.interval</name>
        <value>5</value>
        <valuetype>Integer</valuetype>
        <group>namenode</group>
        <definition>
            <en>The number of nodes namenode checks if decommission is complete</en>
        </definition>
        <description>
            <en>The number of nodes namenode checks if decommission is complete
  in each dfs.namenode.decommission.interval.</en>
        </description>
    </property>
    <property>
        <name>dfs.replication.interval</name>
        <value>3</value>
        <valuetype>Integer</valuetype>
        <group>basic</group>
        <definition>
            <en>The periodicity in seconds with which the namenode computes
  repliaction work for datanodes.</en>
        </definition>
        <description>
            <en>The periodicity in seconds with which the namenode computes
  repliaction work for datanodes. </en>
        </description>
    </property>
    <property>
        <name>dfs.access.time.precision</name>
        <value>3600000</value>
        <valuetype>Integer</valuetype>
        <group>basic</group>
        <definition>
            <en>HDFS file access time precision</en>
        </definition>
        <description>
            <en>The access time for HDFS file is precise upto this value.
               The default value is 1 hour. Setting a value of 0 disables
               access times for HDFS.
</en>
        </description>
    </property>
    <property>
        <name>dfs.support.append</name>
        <value>true</value>
        <valuetype>Boolean</valuetype>
        <group>basic</group>
        <definition>
            <en>Whether HDFS allows appends</en>
        </definition>
        <description>
            <en>Does HDFS allow appends to files?</en>
        </description>
    </property>
    <property>
        <name>dfs.datanode.plugins</name>
        <value></value>
        <valuetype>String</valuetype>
        <allowempty>true</allowempty>
        <group>datanode</group>
        <definition>
            <en>Datanode plugins to be activated</en>
        </definition>
        <description>
            <en>Comma-separated list of datanode plug-ins to be activated.
</en>
        </description>
    </property>
    <property>
        <name>dfs.namenode.plugins</name>
        <value></value>
        <valuetype>String</valuetype>
        <allowempty>true</allowempty>
        <group>namenode</group>
        <definition>
            <en>Namenode plugins to be activated</en>
        </definition>
        <description>
            <en>Comma-separated list of namenode plug-ins to be activated.
</en>
        </description>
    </property>
    <property>
        <name>dfs.datanode.failed.volumes.tolerated</name>
        <value>0</value>
        <valuetype>Integer</valuetype>
        <group>datanode</group>
        <definition>
            <en>The number of volumes that are allowed to
  fail before a datanode stops offering service</en>
        </definition>
        <description>
            <en>The number of volumes that are allowed to
  fail before a datanode stops offering service. By default
  any volume failure will cause a datanode to shutdown.
</en>
        </description>
    </property>
    <property>
        <name>dfs.namenode.delegation.key.update-interval</name>
        <value>86400000</value>
        <valuetype>Integer</valuetype>
        <group>namenode</group>
        <definition>
            <en>Namenode delegation key update interval</en>
        </definition>
        <description>
            <en>The update interval for master key for delegation tokens
       in the namenode in milliseconds.
</en>
        </description>
    </property>
    <property>
        <name>dfs.namenode.delegation.token.max-lifetime</name>
        <value>604800000</value>
        <valuetype>Integer</valuetype>
        <group>namenode</group>
        <definition>
            <en>Namenode delegation key maximum lifetime</en>
        </definition>
        <description>
            <en>The maximum lifetime in milliseconds for which a delegation
      token is valid.
</en>
        </description>
    </property>
    <property>
        <name>dfs.namenode.delegation.token.renew-interval</name>
        <value>86400000</value>
        <valuetype>Integer</valuetype>
        <group>namenode</group>
        <definition>
            <en>Namenode delegation key renewal interval</en>
        </definition>
        <description>
            <en>The renewal interval for delegation token in milliseconds.
</en>
        </description>
    </property>
    <property>
        <name>dfs.drbd.name.dir</name>
        <value>/hadoop/drbd</value>
        <valuetype>Directory</valuetype>
        <hide>true</hide>
        <reserved>true</reserved>
        <group>basic</group>
        <definition>
            <en>Remote backup directory</en>
        </definition>
        <description>
            <en>Setting remote backup directory, this directory must be set in "dfs.name.dir".</en>
        </description>
    <sectionname>NameNode-system</sectionname>
    <form>TextItem</form>
    </property>
    <property>
        <name>hdfs.shortcut.reader.user</name>
        <value></value>
        <valuetype>String</valuetype>
        <allowempty>true</allowempty>
        <reserved>true</reserved>
        <group>datanode</group>
        <definition>
            <en>User when reading local data in datanode</en>
        </definition>
        <description>
            <en>Which user do you want to use when reading local data in datanode.
    Empty value will disable the feature.</en>
        </description>
    </property>
    <property>
        <name>namenode.memory.weight</name>
        <value></value>
        <recommendation>50</recommendation>
        <valuetype>Integer</valuetype>
        <global>true</global>
        <group>namenode</group>
        <definition>
            <en>Weight of namenode heapsize</en>
        </definition>
        <description>
            <en>The weight of namenode heapsize and the default value is 50.</en>
        </description>
    <sectionname>advanced</sectionname>
    <form>TextItem</form>
    </property>
    <property>
        <name>secondary.namenode.memory.weight</name>
        <value></value>
        <recommendation>50</recommendation>
        <valuetype>Integer</valuetype>
        <global>true</global>
        <group>namenode</group>
        <definition>
            <en>Weight of secondary namenode heapsize</en>
        </definition>
        <description>
            <en>The weight of secondary namenode heapsize and the default value is 50.
</en>
        </description>
    </property>
    <property>
        <name>dfs.socket.timeout</name>
        <value>120000</value>
        <valuetype>Integer</valuetype>
        <group>basic</group>
        <definition>
            <en>Timeout for socket connection</en>
        </definition>
        <description>
            <en>Timeout for socket connection.</en>
        </description>
    </property>
    <property>
        <name>dfs.replication.adjust</name>
        <value>false</value>
        <valuetype>Boolean</valuetype>
        <group>replication</group>
        <definition>
            <en>Whether to adjust the replication count</en>
        </definition>
        <description>
            <en>
     If it is true, adjust the number of replication according to visiting numbers of blocks.
  </en>
        </description>
    </property>
    <property>
        <name>dfs.replication.historyWindow</name>
        <value>1440</value>
        <valuetype>Integer</valuetype>
        <group>replication</group>
        <definition>
            <en>Retention cycle time</en>
        </definition>
        <description>
            <en>
     Determines retention cycle time of file visit statistics,(in Minutes), The default value is 1 day.
  </en>
        </description>
    </property>
    <property>
        <name>dfs.replication.adjustTimer</name>
        <value>720</value>
        <valuetype>Integer</valuetype>
        <group>replication</group>
        <definition>
            <en>Replication adjusting interval</en>
        </definition>
        <description>
            <en>
    Determines the file's replication adjusting interval(in Minutes), The default value is 6 hours.
  </en>
        </description>
    </property>
    <property>
        <name>dfs.replication.adjust.maxPercent</name>
        <value>0.1</value>
        <valuetype>Float</valuetype>
        <group>replication</group>
        <definition>
            <en>Replica adjusting max percentage of disk space</en>
        </definition>
        <description>
            <en>
     The max percentage of disk space for replica adjusting.
  </en>
        </description>
    </property>
    <property>
        <name>dfs.replication.reserved.datanode.number.percent</name>
        <value>0.1</value>
        <valuetype>Float</valuetype>
        <group>replication</group>
        <definition>
            <en>Percentage of datanode numbers reserved to others</en>
        </definition>
        <description>
            <en>
     The percentage of Datanode numbers for reserving to others.
  </en>
        </description>
    </property>
    <property>
        <name>dfs.replication.adjust.blockWeight</name>
        <value>10</value>
        <valuetype>Integer</valuetype>
        <group>replication</group>
        <definition>
            <en>Number of blocks for adjust weight</en>
        </definition>
        <description>
            <en>
     The number of blocks to be regarded as a basic unit for adjust weight.
  </en>
        </description>
    </property>
    <!--
    <property>
        <name>dfs_namenode_name_dir</name>
        <value>/hadoop/drbd/hadoop_image,/hadoop/hadoop_image_local</value>
        <valuetype>String</valuetype>
        <group>namenode</group>
        <definition>
            <en>NameNode Directory</en>
        </definition>
        <sectionname>NameNode-system</sectionname>
        <description>
            <en>Determines where on the local filesystem the DFS name node should store the name table(fsimage).  If this is a comma-delimited list of directories then the name table is replicated in all of the directories, for redundancy.</en>
        </description>
        <form>TextItem</form>
    </property>
    -->
    <briefsection>
        <sectionname>basic</sectionname>
        <name_en>HDFS Basic</name_en>
        <autoexpand>true</autoexpand>
        <showdescription>false</showdescription>
    </briefsection>
    <briefsection>
        <sectionname>NameNode-system</sectionname>
        <name_en>NameNode Configuration</name_en>
        <autoexpand>true</autoexpand>
        <showdescription>false</showdescription>
        <description_en>""</description_en>
    </briefsection>
    <briefsection>
        <sectionname>advanced</sectionname>
        <name_en>Advanced Configuration</name_en>
        <autoexpand>true</autoexpand>
        <showdescription>false</showdescription>
        <description_en>""</description_en>
    </briefsection>
    <group>
        <id>basic</id>
        <name_en>Basic Configuration</name_en>
        <description_en>Basic configurations that get HDFS running.</description_en>
    </group>
    <group>
        <id>perf</id>
        <name_en>Performance</name_en>
        <description_en>Configurations that affect Hadoop's performance</description_en>
    </group>
    <group>
        <id>namenode</id>
        <name_en>Namenode Configuration</name_en>
        <description_en>Configurations for Namenode.</description_en>
    </group>
    <group>
        <id>datanode</id>
        <name_en>Datanode Configuration</name_en>
        <description_en>Configurations for Datanode.</description_en>
    </group>
    <group>
        <id>security</id>
        <name_en>Security</name_en>
        <description_en>Security configurations like permission control.</description_en>
    </group>
    <group>
        <id>replication</id>
        <name_en>Replication</name_en>
        <description_en>Configurations for replication</description_en>
    </group>
</configuration>
